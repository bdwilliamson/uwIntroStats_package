<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Brian D. Williamson and Scott S. Emerson, MD PhD" />

<meta name="date" content="2015-07-24" />

<title>Using the uwIntroStats Package</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0A%7D%0Apre%20%7B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>



<div id="header">
<h1 class="title">Using the <code>uwIntroStats</code> Package</h1>
<h3 class="subtitle"><em>University of Washington Department of Biostatistics</em></h3>
<h4 class="author"><em>Brian D. Williamson and Scott S. Emerson, MD PhD</em></h4>
<h4 class="date"><em>2015-07-24</em></h4>
</div>

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a><ul>
<li><a href="#preparing-uwintrostats">Preparing <code>uwIntroStats</code></a></li>
</ul></li>
<li><a href="#descriptive-statistics">Descriptive Statistics</a><ul>
<li><a href="#the-basics-descrip">The basics: <code>descrip()</code></a></li>
<li><a href="#tablestat-and-tabulate-flexible-functions"><code>tableStat()</code> and <code>tabulate()</code>: Flexible Functions</a></li>
</ul></li>
<li><a href="#plotting">Plotting</a><ul>
<li><a href="#boxplots">Boxplots</a></li>
<li><a href="#scatterplots">Scatterplots</a></li>
</ul></li>
<li><a href="#transformations-of-a-variable">Transformations of a Variable</a><ul>
<li><a href="#dummy-variables">Dummy Variables</a></li>
<li><a href="#linear-splines">Linear Splines</a></li>
<li><a href="#polynomials">Polynomials</a></li>
</ul></li>
<li><a href="#one-and-two-sample-functions">One and Two Sample Functions</a><ul>
<li><a href="#correlation">Correlation</a></li>
<li><a href="#point-estimates-and-inference">Point Estimates and Inference</a></li>
</ul></li>
<li><a href="#regression">Regression</a><ul>
<li><a href="#basics-of-regress">Basics of <code>regress()</code></a></li>
<li><a href="#regression-on-different-functionals">Regression on different functionals</a></li>
<li><a href="#correlated-data-regression">Correlated data regression</a></li>
<li><a href="#multiple-partial-f-tests">Multiple-partial F-tests</a></li>
</ul></li>
<li><a href="#post-estimation">Post Estimation</a><ul>
<li><a href="#linear-combinations-of-regression-coefficients">Linear Combinations of Regression Coefficients</a></li>
<li><a href="#prediction">Prediction</a></li>
</ul></li>
<li><a href="#diagnostics">Diagnostics</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>Introduction</h1>
<div id="preparing-uwintrostats" class="section level2">
<h2>Preparing <code>uwIntroStats</code></h2>
<p>Before we can dive in and run any analyses, we first need to install the package. This is done via</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;uwIntroStats&quot;</span>)</code></pre></div>
<p>Regardless of the graphical user interface (GUI) that you are using, R will prompt you to select a CRAN mirror. It is essentially asking you where you want to download the package files from. Select the mirror closest to you - for us at the University of Washington it is <code>WA(1)</code> or the Fred Hutchinson Cancer Research Center (FHCRC) - and the package will download and say that it has installed. Now each time we open a new R session (whether that is at the command line, a new RGui window, or a new RStudio window) we need to load the package for use.</p>
<p>Five other packages provide a few key functions that the <code>uwIntroStats</code> package uses or adds functionality to. We must install these packages like we did above if we have not installed them previously, and then load <code>uwIntroStats</code>. While the packages do not need to be loaded every time (in fact, some are only used for specific functions) it is good practice to load them for the R session where you need to use <code>uwIntroStats</code>. This makes sure that we can use their other functions while doing analyses.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(Exact)
<span class="kw">library</span>(geepack)
<span class="kw">library</span>(plyr)
<span class="kw">library</span>(sandwich)
<span class="kw">library</span>(survival)
<span class="kw">library</span>(uwIntroStats)</code></pre></div>
<p>Don’t worry about the warning message for now; that will be covered in section 3.2. Last, we load the data, <code>mri</code> that we will be using throughout this document. Information about the dataset can be found at <a href="http://www.emersonstatistics.com/datasets/mri.pdf">mri.pdf</a>. Since the data is part of the package, we can load it via</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(mri)</code></pre></div>
<p>The <code>uwIntroStats</code> package should be used for descriptive statistics, basic plotting (like scatterplots and boxplots), and regression analyses. The following sections will go through examples of these tasks, in addition to pointing out how our package differs from base R and other existing packages. We will assume familiarity with basic data manipulation and statistical tasks (for a refresher, see <a href="http://www.emersonstatistics.com/GeneralMaterials/R/IntroToR.pdf">“An Introduction to R”</a>.</p>
</div>
</div>
<div id="descriptive-statistics" class="section level1">
<h1>Descriptive Statistics</h1>
<p>Descriptive statistics are an important part of any analysis. Often, they are just as important for the statistician or data analysist as they are for the scientific collaborators on a project. For example, descriptive statistics can help identify errors in the data, like observations that are particularly unusual (usually far out of the expected or observed range). They can also help to identify patterns of missing data, examine the study population, and identify aspects of the data that might lead to statistical issues. Descriptive statistics can also unearth relationships that had not previously been considered for analysis, thereby generating new studies. More information on this, and an outline of an approach to analysing a dataset, <a href="http://www.emersonstatistics.com/GeneralMaterials/analysis.pdf">“Organizing Your Approach to a Data Analysis”</a>, was written by Scott Emerson for this purpose.</p>
<div id="the-basics-descrip" class="section level2">
<h2>The basics: <code>descrip()</code></h2>
<p>The <code>uwIntroStats</code> package was designed with descriptive statistics in mind. The basic function for descriptive statistics is <code>descrip()</code>. This function takes in an arbitrary number of variables, and by default calculates the number of observations, the number of missing values, the mean, standard deviation, mininum value, maximum value, and the 25th, 50th, and 75th percentiles of each variable. For instance, if we wanted a quick glance at the <code>mri</code> data, we could type</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">descrip</span>(mri)</code></pre></div>
<pre><code>##             N     Msng  Mean      Std Dev    Min       25%       Mdn     
##     ptid:     735     0   368.0     212.3     1.000     184.5     368.0  
##  mridate:     735     0   76423     31896     10192     66642     80992  
##      age:     735     0   74.57     5.451     65.00     71.00     74.00  
##     male:     735     0   0.4980    0.5003    0.0000    0.0000    0.0000 
##     race:     735     0   1.318     0.6659    1.000     1.000     1.000  
##   weight:     735     0   159.9     30.74     74.00     138.5     158.0  
##   height:     735     0   165.8     9.710     139.0     158.0     165.9  
##  packyrs:     735     1   19.60     27.11     0.0000    0.0000    6.500  
##  yrsquit:     735     0   9.661     14.10     0.0000    0.0000    0.0000 
##    alcoh:     735     0   2.109     4.852     0.0000    0.0000   0.01920 
##  physact:     735     0   1.922     2.052     0.0000    0.5538    1.312  
##      chf:     735     0  0.05578    0.2297    0.0000    0.0000    0.0000 
##      chd:     735     0   0.3347    0.6862    0.0000    0.0000    0.0000 
##   stroke:     735     0   0.2367    0.6207    0.0000    0.0000    0.0000 
## diabetes:     735     0   0.1075    0.3099    0.0000    0.0000    0.0000 
##  genhlth:     735     0   2.588     0.9382    1.000     2.000     3.000  
##      ldl:     735    10   125.8     33.60     11.00     102.0     125.0  
##      alb:     735     2   3.994     0.2690    3.200     3.800     4.000  
##      crt:     735     2   1.064     0.3030    0.5000    0.9000    1.000  
##      plt:     735     7   246.0     65.80     92.00     201.8     239.0  
##      sbp:     735     0   131.1     19.66     78.00     118.0     130.0  
##      aai:     735     9   1.103     0.1828    0.3171    1.027     1.112  
##      fev:     735    10   2.207     0.6875    0.4083    1.745     2.158  
##     dsst:     735    12   41.06     12.71     0.0000    32.00     40.00  
##  atrophy:     735     0   35.98     12.92     5.000     27.00     35.00  
##    whgrd:     735     1   2.007     1.410     0.0000    1.000     2.000  
##   numinf:     735     0   0.6109    0.9895    0.0000    0.0000    0.0000 
##   volinf:     735     1   3.223     17.36     0.0000    0.0000    0.0000 
##  obstime:     735     0    1804     392.3     68.00      1837      1879  
##    death:     735     0   0.1810    0.3852    0.0000    0.0000    0.0000 
##              75%       Max      
##     ptid:     551.5      735.0  
##  mridate:     91392    1.232e+05
##      age:     78.00      99.00  
##     male:     1.000      1.000  
##     race:     1.000      4.000  
##   weight:     179.0      264.0  
##   height:     173.2      190.5  
##  packyrs:     33.75      240.0  
##  yrsquit:     18.50      56.00  
##    alcoh:     1.144      35.00  
##  physact:     2.513      13.81  
##      chf:     0.0000     1.000  
##      chd:     0.0000     2.000  
##   stroke:     0.0000     2.000  
## diabetes:     0.0000     1.000  
##  genhlth:     3.000      5.000  
##      ldl:     147.0      247.0  
##      alb:     4.200      5.000  
##      crt:     1.200      4.000  
##      plt:     285.0      539.0  
##      sbp:     142.0      210.0  
##      aai:     1.207      1.728  
##      fev:     2.649      4.471  
##     dsst:     50.00      82.00  
##  atrophy:     44.00      84.00  
##    whgrd:     3.000      9.000  
##   numinf:     1.000      5.000  
##   volinf:    0.09420     197.0  
##  obstime:      2044      2159   
##    death:     0.0000     1.000</code></pre>
<p>This call gives us a quick look at the distribution of each variable in the sample, and can be easily exported to a word processing software. This is important, because displaying raw R output in a publication is not usually ideal, and taking the time to format the output is a pain.</p>
<p>Notice that there are a lot of variables measured in these data, and that some interesting phenomena are measured by multiple variables. For instance, smoking is measured by <code>packyrs</code> and <code>yrsquit</code> - if someone has zero pack-years (that is, they have never smoked) then they will also have zero years quit. Similarly, a current smoker of any amount of packs per year will have zero years quit. We can also look at the variables measured through blood samples, like LDL cholesterol (<code>ldl</code>) and get an idea of the range in our sample population. Last, in the variables like <code>male</code> which consist of only two values (sex was measured as male or female in this dataset), the mean tells us the proportion of our sample who was male (or for other binary variables, it will tell us the proportion which is coded as 1). The <code>descrip()</code> function works similarly to <code>summary()</code> in base R, but gives more information and returns it in a format that, as we described above, is easier to export from R.</p>
<p>Another powerful feature of <code>descrip()</code> is its ability to present stratified summaries, or summaries on a subset of the data. For instance, let’s calculate descriptive statistics on the <code>age</code> variable within males and females:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">descrip</span>(mri$age, <span class="dt">strata =</span> mri$male)</code></pre></div>
<pre><code>##                    N     Msng  Mean      Std Dev    Min       25%     
## mri$age:  All        735     0   74.57     5.451     65.00     71.00  
## mri$age:    Str  0   369     0   74.41     5.258     65.00     71.00  
## mri$age:    Str  1   366     0   74.73     5.642     66.00     71.00  
##                     Mdn       75%       Max     
## mri$age:  All        74.00     78.00     99.00  
## mri$age:    Str  0   73.00     78.00     91.00  
## mri$age:    Str  1   74.00     78.00     99.00</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Call the summary function, to compare
<span class="kw">summary</span>(mri$age)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   65.00   71.00   74.00   74.57   78.00   99.00</code></pre>
<p>Here the row for <code>Str 0</code> corresponds to females (since they are coded as 0 for <code>male</code>), and males are <code>Str 1</code>. If we further wanted to restrict to only those people who were over 75 years old, we could use the <code>subset</code> argument:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">descrip</span>(mri$age, <span class="dt">strata =</span> mri$male, <span class="dt">subset =</span> mri$age &gt;<span class="st"> </span><span class="dv">75</span>)</code></pre></div>
<pre><code>##                    N     Msng  Mean      Std Dev    Min       25%     
## mri$age:  All        260     0   80.59     4.111     76.00     77.75  
## mri$age:    Str  0   127     0   80.44     3.572     76.00     78.00  
## mri$age:    Str  1   133     0   80.73     4.576     76.00     77.00  
##                     Mdn       75%       Max     
## mri$age:  All        79.00     83.00     99.00  
## mri$age:    Str  0   79.00     83.00     91.00  
## mri$age:    Str  1   79.00     83.00     99.00</code></pre>
<p>However, the <code>descrip()</code> function can only give us a fixed number of summaries (mean, count, etc). Oftentimes we need only a subset of these, or perhaps different summary measures. For this, we turn to more powerful functions.</p>
</div>
<div id="tablestat-and-tabulate-flexible-functions" class="section level2">
<h2><code>tableStat()</code> and <code>tabulate()</code>: Flexible Functions</h2>
<p>The main draw of <code>tableStat()</code> and <code>tabulate()</code> is their ability to supply only a subset of the summary measures from <code>descrip()</code>. These functions focus on display and flexibility. The user supplies the format for the summary statistics to be displayed in, which makes exporting results from a call to <code>tablestat()</code> or <code>tabulate()</code> even easier than it was for <code>descrip()</code>. Of the two, <code>tableStat()</code> is the base, and <code>tabulate()</code> adds some additional formatting and options. For example, let’s say that we want the same summary statistics as we would get from <code>descrip()</code>, but we want to control the printout. For this, we use the <code>stat</code> argument to <code>tableStat()</code>. The options are presented in below.</p>
<p><a id="stattable"></a></p>
<table>
<thead>
<tr class="header">
<th align="left">Name</th>
<th align="left">Summary Measure</th>
<th align="left">Name</th>
<th align="left">Summary Measure</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>&quot;count&quot;</code></td>
<td align="left">Number of observations on a variable</td>
<td align="left"><code>&quot;sd&quot;</code></td>
<td align="left">Standard Deviation</td>
</tr>
<tr class="even">
<td align="left"><code>&quot;missing&quot;</code></td>
<td align="left">Number of missing observations</td>
<td align="left"><code>&quot;variance&quot;</code></td>
<td align="left">Variance</td>
</tr>
<tr class="odd">
<td align="left"><code>&quot;mean&quot;</code></td>
<td align="left">Arithmetic mean</td>
<td align="left"><code>&quot;min&quot;</code></td>
<td align="left">Minimum value</td>
</tr>
<tr class="even">
<td align="left"><code>&quot;geometric mean&quot;</code></td>
<td align="left">Geometric mean</td>
<td align="left"><code>&quot;max&quot;</code></td>
<td align="left">Maximum value</td>
</tr>
<tr class="odd">
<td align="left"><code>&quot;median&quot;</code></td>
<td align="left">50th percentile</td>
<td align="left"><code>&quot;quantiles&quot;</code></td>
<td align="left">Display quantiles</td>
</tr>
<tr class="even">
<td align="left"><code>&quot;probabilities&quot;</code></td>
<td align="left">Display percentiles</td>
<td align="left"><code>&quot;mn(sd)&quot;</code></td>
<td align="left">Display Mean (SD) format</td>
</tr>
<tr class="odd">
<td align="left"><code>&quot;range&quot;</code></td>
<td align="left">Maximum value - minimum value</td>
<td align="left"><code>&quot;iqr&quot;</code></td>
<td align="left">Interquartile range (75th - 25th percentiles)</td>
</tr>
<tr class="even">
<td align="left"><code>&quot;all&quot;</code></td>
<td align="left">Display all summary measures</td>
<td align="left"><code>&quot;row%&quot;</code></td>
<td align="left">Display row percentages</td>
</tr>
<tr class="odd">
<td align="left"><code>&quot;col%&quot;</code></td>
<td align="left">Display column percentages</td>
<td align="left"><code>&quot;tot%&quot;</code></td>
<td align="left">Display percentage of total</td>
</tr>
</tbody>
</table>
<p>The following gets us close to results we could display in a table for a puplication. We want to have <span class="math display">\[
N: \ n; \ Mean \ (SD): \ mn \ (sd); \ Range: \ max - min,
\]</span> which we get via:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tableStat</span>(mri$age, <span class="dt">stat =</span> <span class="st">&quot;N: @count@; Mean (SD): @mean@ (@sd@); Range: @max@ - @min@&quot;</span>)</code></pre></div>
<pre><code>## Tabled descriptive statistics by strata
## Call:
##       tableStat(variable = mri$age, stat = &quot;N: @count@; Mean (SD): @mean@ (@sd@); Range: @max@ - @min@&quot;) 
##             - NaN denotes strata with no observations
##             - NA arises from missing or censored data
## 
## Format:  N: Cnt; Mean (SD): Mean (SD); Range: Max - Min 
## 
##                                                     .ALL 
## N: 735.0; Mean (SD): 74.57 (5.451); Range: 99.00 - 65.00</code></pre>
<p>Note that all of the values enclosed in  symbols are from Table  and are run by , while the other values in the string are used for formatting. This function can also take stratification variables; if we want to see the above stratified by sex, we use</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tableStat</span>(mri$age, <span class="dt">strata =</span> mri$male, <span class="dt">stat =</span> <span class="st">&quot;N: @count@; Mean (SD): @mean@ (@sd@); Range: @min@ - @max@&quot;</span>)</code></pre></div>
<pre><code>## Tabled descriptive statistics by strata
## Call:
##       tableStat(variable = mri$age, strata = mri$male, stat = &quot;N: @count@; Mean (SD): @mean@ (@sd@); Range: @min@ - @max@&quot;) 
##             - NaN denotes strata with no observations
##             - NA arises from missing or censored data
## 
## Format:  N: Cnt; Mean (SD): Mean (SD); Range: Min - Max 
## 
##                                                 strata.0 
## N: 369.0; Mean (SD): 74.41 (5.258); Range: 65.00 - 91.00 
##                                                 strata.1 
## N: 366.0; Mean (SD): 74.73 (5.642); Range: 66.00 - 99.00 
##                                               strata.ALL 
## N: 735.0; Mean (SD): 74.57 (5.451); Range: 65.00 - 99.00</code></pre>
<p>Now if we wanted to see this in table form, in perhaps a nicer layout, we could use the <code>tabulate()</code> function. When we loaded the <code>uwIntroStats</code> package at the beginning of this document, recall that we got a warning message from R saying</p>
<pre><code>The following object is masked from ‘package:base’:

    tabulate</code></pre>
<p>This means that our function <code>tabulate()</code> overwrites the function called <code>tabulatte()</code> in the base R package, which takes a numeric vector and counts the number of times each integer occurs in it. Our function does a similar task, but on combinations of strata. The syntax is very similar to the syntax for <code>tableStat()</code>, but rather than explicitly telling <code>tabulate()</code> the strata, it creates the tables with each dimension corresponding to a variable in the order they are entered. For instance, if we want a table of <code>age</code> (in the rows) and <code>male</code> (in the columns), we would write</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tabulate</span>(mri$age, mri$male)</code></pre></div>
<pre><code>## 
## Call:
## tabulate(mri$age, mri$male)
##             mri$male.0 mri$male.1 mri$male.ALL
## mri$age.65    2          0          2         
## mri$age.66    2          1          3         
## mri$age.67   18         15         33         
## mri$age.68   20         21         41         
## mri$age.69   19         19         38         
## mri$age.70   30         30         60         
## mri$age.71   37         39         76         
## mri$age.72   31         28         59         
## mri$age.73   27         28         55         
## mri$age.74   29         26         55         
## mri$age.75   27         26         53         
## mri$age.76   11         17         28         
## mri$age.77   18         19         37         
## mri$age.78   18         19         37         
## mri$age.79   19         13         32         
## mri$age.80    8         15         23         
## mri$age.81   10         10         20         
## mri$age.82   10          5         15         
## mri$age.83   10          2         12         
## mri$age.84    5          6         11         
## mri$age.85    3          6          9         
## mri$age.86    5          5         10         
## mri$age.87    4          4          8         
## mri$age.88    2          1          3         
## mri$age.89    2          3          5         
## mri$age.90    0          4          4         
## mri$age.91    2          0          2         
## mri$age.92    0          1          1         
## mri$age.94    0          1          1         
## mri$age.95    0          1          1         
## mri$age.99    0          1          1         
## mri$age.ALL 369        366        735         
##             Point Estimate Test Statistic df 95% CI p-value Warnings
## Chi-squared                26.244         30        0.66262</code></pre>
<p>By default, <code>tabulate()</code> gives us the count in each combination of the strata, and gives us the overall <span class="math inline">\(\chi^2\)</span> test statistic, degrees of freedom, and p-value. We can add in other arguments as well. Let’s say that we are interested in an odds ratio or a risk ratio - <code>tabulate()</code> can supply these, if we set <code>dispRatios = TRUE</code>. This is where our use of the <code>Exact</code> package comes in, because this package contains some very useful functions for calculating these ratios. However, we supply both the odds ratio and the risk ratio, even though in some cases only one is appropriate. Thus it is up to the user to know which they can use. To display these ratios for <code>male</code> versus <code>chf</code> (an indicator variable of whether the patient had been diagnosed with congestive heart failure prior to MRI), we type</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tabulate</span>(mri$male, mri$chf, <span class="dt">dispRatios =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
## Call:
## tabulate(mri$male, mri$chf, dispRatios = TRUE)
##              mri$chf.0 mri$chf.1 mri$chf.ALL
## mri$male.0   354        15       369        
## mri$male.1   340        26       366        
## mri$male.ALL 694        41       735        
##             Point Estimate Test Statistic df 95% CI           p-value 
## Chi-squared                3.2214         1                   0.072679
## Odds Ratio  1.8047                           [0.9396, 3.4663]         
## Risk Ratio  1.2944                           [1.0136, 1.6531]         
##             Warnings
## Chi-squared         
## Odds Ratio          
## Risk Ratio</code></pre>
<p>Now we are given a point estimate and a 95% confidence interval for both the odds and risk ratio, in addition to the <span class="math inline">\(\chi^2\)</span> estimate.</p>
<p>Last, similar to <code>tableStat()</code>, we can identify different statistics to display. The syntax is exactly the same, and the same statistics from <a href="#stattable">Table 1</a> are valid in <code>tabulate()</code>.</p>
</div>
</div>
<div id="plotting" class="section level1">
<h1>Plotting</h1>
<p>Plots and descriptive statistics together lead to a much better understanding of the data. In our package, we have implemented two types of plots: boxplots and scatterplots. In doing so, we have attempted to address some concerns with both types of plots.</p>
<div id="boxplots" class="section level2">
<h2>Boxplots</h2>
<p>Boxplots reduce the data down to four summary measures: minimum, maximum, median, and the interquartile range (25th to 75th quantile). They also show “outliers” in the data. We put this in quotes because the definition of “outlier” depends on the function you call, and the software you are running. Even in the base R version, <code>boxplot()</code>, the boxplots can be constructed so that no outliers are shown.</p>
<p>Much of the criticism of boxplots lies both in this determination of outliers and in the dramatic reduction of the data. In our version, <code>bplot()</code>, we have added jittered data onto the boxplots (jittering allows us to see the data, but randomly adds noise so that we can see individual points better), and we have added the mean and standard deviation onto the plot. We can also produce stratified boxplots. For our function, the variable on the y-axis comes first, followed by the variable on the x-axis. This convention, while at odds with base R, is an attempt to make our functions match up with the regression scheme of response followed by predictors.</p>
<p>For our first example, let’s create a boxplot showing the age distribution of the <code>diabetes</code> variable:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Base R boxplot
<span class="kw">boxplot</span>(mri$age ~<span class="st"> </span>mri$diabetes)</code></pre></div>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASAAAAEgCAMAAAAjXV6yAAAAQlBMVEUAAAAAADoAAGYAOpAAZrY6AAA6ADo6AGY6kNtmAABmtv+QOgCQ2/+2ZgC2///bkDrb////tmb/25D//7b//9v////ed2O8AAAACXBIWXMAAA7DAAAOwwHHb6hkAAAFEUlEQVR4nO2d3XKbMBQGSZr+pKnjOqnf/1VrwJnxhWENHFnmsHuRyYXyHbwjJFlAaI4ySlP7AB4dBQEKAhQEKAhQEKAgQEGAggAFAQoCFAQoCFAQoCBAQYCCAAUBCgIUBCgIUBCgIEBBgIIABQEKAhQEKAhQEKAgQEGAggAFAQoCFAQoCFAQoCBAQYCCAAUBCgIUBCgIUBCgIEBBgIIABQEKAhQEKAhQEKAgQEGAggAFAQoCFAQoCFAQoCBAQYCCAAUBCgIUBCgIUBCgIEBBgIIABQEKAhQEKAgIFtSshvsKml73/Fch1edwZ0Gz4pr48tOKxzYMj2tK1J9YPbJheJyCbmqqoPG2jkGjjbPNYp+vv04/D6fP9fweEFeVcoL23/62v/1eHleVYoLOajpNC+OqUkzQx/dO0GHgJFOQPWiEz9f229bL8Wu4XhiXbxY7do6e/pwmsgE/roMC4za1kp6z3ZFS0L+3XsPAKmhiD2p95hL08ePPaQI7zfC7oaX0tsegf2/d2Lw7/dy9LI5L2IMu1kABC8WEY9BXD3rpz7OFcQkFHfenNVA3EH2+Lj/FEo5B/VbH04ifmivpaWkrWCgGM7E/bk7Q1BFtFYIiT7GMgkIH6YSCgqf5fGNQ9Eo63SzWfZ5qW2YKourhDcdTZu0HpfuyGhu3qR40J05B2NRT7IamChpvm227Y2Fc1J2nQ+FhBzqnYYm40O2gaXmbE5Twy2pscQXdFJVNUHTldGPQwlpL5sQtCFpUex2CYos/sqCZa73tCJoZp6D7Fi9SWkFRDavElWOLghKOQRVrFxL0dRNn0NM+6Wax/dcN5IN3km9b0PkWvJaYZzWyCbp4SizmaZ9s0/yD96AypSeOQecuFDQGVaTQLNY/ENU0A/3Haf7eceVqu90R1XjaMe6a5qVbLA497rNxQe3ctWufyYx5JDOdoG6aP7SPIzjNX6VbKPZLRBeK1wjvQRUpPAZdrKnH4ujKVezdHvXHoMmz2ML+tEJBE+MUBHHBgiJP2JyCAtMUBGkKgjQFQZqCIO0xtjsUFHUUt4QpCMJcB0GYgiAspaDIj5RyDFIQHIWCgo7iljAFQZiCIExBEJZSkIP0sriJxRVEzQP742Nsdzww6+hBFVEQsA5BscUnpSkoqrGCIlOj47IJCn91TUpBvrpmGF88AvjqGiC8B+Ubg9pvW3Gvrkkn6Bj76pqUgmLjtiPoxu2OiTuINxedkVZIUPtGlo/v3T/+j4irSBlBnZ/29TUuFK/SzV39S2tcKF6j7TfnhxBcKF6le2nNeA9aDUUEfb4+v1888rOYitN8qdRDr3/ozTVli981rWxqleIKumta2dQqxRV017SyqVWKK+iuaWVTqxRPKGgNKAhQEKAgQEGAggAFAQoCFAQoCFAQoCBAQUA9QYeRK9hz+Pg5dOPkIqoJaq8cBV096mgvSYWFXVBLUH+Fdhd0/ajrj7kE9fc67qM+1KH5NXQ1fCHVBLU3iQxe4p9DMkH98BM5CCmIEnMJ8hQDggfpYzpB0dN8OkHhC8V0go774K8a6QStBAUBCgIUBCgIUBCgIEBBgIIABQEKAhQEKAhQEKAgQEGAggAFAQoCFAQoCFAQoCBAQYCCAAUBCgIUBCgIUBCgIEBBgIIABQEKAhQEKAhQEKAgQEGAggAFAQoCFAQoCFAQoCBAQYCCAAUBCgIUBCgIUBCgIEBBgIIABQEKAhQEKAhQEKAg4D+Bb/jM2pvsjgAAAABJRU5ErkJggg==" alt /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Our version of boxplot
<span class="kw">bplot</span>(mri$age, mri$diabetes)</code></pre></div>
<p><img src="data:image/png;base64,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" alt /></p>
<p>In comparing the two, see that our plot displays the mean line and <span class="math inline">\(\pm\)</span> standard deviation box in blue and overlays the jittered data on top of the boxplots produced by the base R function. Now if we also wanted to stratify by race, we write</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bplot</span>(mri$age, mri$diabetes, <span class="dt">strata =</span> mri$race)</code></pre></div>
<p><img src="data:image/png;base64,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" alt /></p>
<p>This boxplot breaks down diabetes by race, again showing the mean and standard deviation bars. Note that like normal plots, we can define the axis labels and title by hand.</p>
</div>
<div id="scatterplots" class="section level2">
<h2>Scatterplots</h2>
<p>Scatterplots are a very common way to view data. They plot all of the data in one window, which allows the user to get a good overall view. However, many times the data is clumped together in some spots, and it is hard to see all of the points. Thus, similar to our approach in <code>bplot()</code>, our <code>scatter()</code> function jitters the data slightly by default. To illustrate this difference, we consider the distribution of cerebral atrophy by age group. In the base R scatterplot,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(mri$age, mri$atrophy)</code></pre></div>
<p><img src="data:image/png;base64,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" alt /></p>
<p>we see that a lot of the values sit on top of each other. In our version (which again uses the Y followed by X convention),</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">scatter</span>(mri$atrophy, mri$age)</code></pre></div>
<p><img src="data:image/png;base64,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" alt /></p>
<p>the jittered data allows us to see where all of the points lie much better. Also notice that <code>scatter()</code> displayes a loess curve by default. We can also display a line of best fit calculated by least squares by adding <code>plotLSfit = TRUE</code>. Last, we can stratify, which is particularly useful if we want to see differences across a third variable, and <code>scatter()</code> will automatically color the data appropriately:</p>
<p><a id="stratscatter"></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">scatter</span>(mri$atrophy, mri$age, <span class="dt">strata =</span> mri$race)</code></pre></div>
<p><img src="data:image/png;base64,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" alt /></p>
</div>
</div>
<div id="transformations-of-a-variable" class="section level1">
<h1>Transformations of a Variable</h1>
<p>In many cases (especially in regression, which we will cover in section 7), it is more useful to model a transformation of a variable than the raw data itself. We present three functions to easily transform a variable. In each case, the function returns a list of: a matrix with the new transformed variable, the type of transformation performed, a vector describing how the variable was created, the name of the created variable, and the original data.</p>
<div id="dummy-variables" class="section level2">
<h2>Dummy Variables</h2>
<p>Dummy variables are a convenient way of creating indicator variables against some reference. For example, in the <code>mri</code> data, if we wanted to create a dummy variable for <code>race</code>, this would create 3 indicator variables (since there are four levels of race). By default, our <code>dummy()</code> function creates these indicators using the smallest value as the reference.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dummy.race &lt;-<span class="st"> </span><span class="kw">dummy</span>(mri$race)
<span class="kw">head</span>(dummy.race, <span class="dt">n =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>##       2 vs 1 3 vs 1 4 vs 1
##  [1,]      1      0      0
##  [2,]      1      0      0
##  [3,]      1      0      0
##  [4,]      0      0      0
##  [5,]      0      0      0
##  [6,]      0      0      1
##  [7,]      0      0      0
##  [8,]      1      0      0
##  [9,]      0      0      0
## [10,]      0      0      0</code></pre>
<p>Thus the set of dummy variables for race created above has: an indicator of whether the patient is black or white, an indicator of whether the patient is Asian or white, and an indicator of whether the patient is listed as ``other’’ or white. These variables would allow us, in a regression, to compare each of the races against the white reference group.</p>
</div>
<div id="linear-splines" class="section level2">
<h2>Linear Splines</h2>
<p>Linear splines create a piecewise linear fit between user specified “knot” points; these are the points in the variable that we allow the slope of the line to change. There are two major ways to parameterize linear splines, and we have implemented both in this package. The first is based on the absolute slope between knots - that is, if we had a variable (like <code>ldl</code> in the <code>mri</code> dataset) that took on values between 11 and 247 and we placed knots at 70 and 150, we would see three columns: the first would show the minimum of 70 and the value of <code>ldl</code>; the second would show the minimum of <code>ldl</code> - 70 and 80; and the last column would show the remaining part of <code>ldl</code>. For example, if <code>ldl</code> = 71 for one patient, we would see <code>70 1 0</code>. If  = 247, we would see <code>70 80 97</code>.</p>
<p>The second parameterization is denoted by us as “change”. This uses the change between knots to specify the slopes. Under this parameterization, we would see, for a value of 115, <code>115 45 0</code>, which corresponds to: 115 units between the minimum and the value, 45 units between knot 1 (at 70) and the value, and zero units between knot 2 (at 150) and the value. We do not show negative units.</p>
<p>These two parameterizations can be accessed via</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lspline.ldl &lt;-<span class="st"> </span><span class="kw">lspline</span>(mri$ldl, <span class="dt">knots =</span> <span class="kw">c</span>(<span class="dv">70</span>, <span class="dv">150</span>))
<span class="kw">head</span>(lspline.ldl, <span class="dt">n =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>##   $ mri ldl
##  70  65   0
##  70  14   0
##  70  45   0
##  61   0   0
##  70  78   0
##  70  80  13
##  70  31   0
##  70  46   0
##  70  54   0
##  70  40   0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lsplineD.ldl &lt;-<span class="st"> </span><span class="kw">lsplineD</span>(mri$ldl, <span class="dt">knots =</span> <span class="kw">c</span>(<span class="dv">70</span>, <span class="dv">150</span>))
<span class="kw">head</span>(lsplineD.ldl, <span class="dt">n =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>##  x:min x: 70 x:150
##    135    65     0
##     84    14     0
##    115    45     0
##     61     0     0
##    148    78     0
##    163    93    13
##    101    31     0
##    116    46     0
##    124    54     0
##    110    40     0</code></pre>
</div>
<div id="polynomials" class="section level2">
<h2>Polynomials</h2>
<p>Last we come to polynomials. This function creates a polynomial of the specified degree simply by multiplying the variable by itself the correct number of times. If we wanted to create a parabola in <code>age</code>, we type</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">age.parabola &lt;-<span class="st"> </span><span class="kw">polynomial</span>(mri$age, <span class="dt">degree =</span> <span class="dv">2</span>)
<span class="kw">head</span>(age.parabola, <span class="dt">n =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>##       Linear(ctr) Square(ctr)
##  [1,]  -2.5659864   6.5842862
##  [2,]   6.4340136  41.3965311
##  [3,]  15.4340136 238.2087760
##  [4,]  -2.5659864   6.5842862
##  [5,]  -4.5659864  20.8482318
##  [6,]  -2.5659864   6.5842862
##  [7,]   0.4340136   0.1883678
##  [8,]   0.4340136   0.1883678
##  [9,]  -7.5659864  57.2441501
## [10,]  -4.5659864  20.8482318</code></pre>
<p>The “(ctr)” after each term tells us that <code>polynomial()</code> has automatically centered each term, and by default it centers at the mean of the variable.</p>
</div>
</div>
<div id="one-and-two-sample-functions" class="section level1">
<h1>One and Two Sample Functions</h1>
<p>Many of our analyses boil down to one-sample or two-sample problems; What is the mean time to death? What is the median home price in Seattle? What is the difference in mean time to death between control and the treatment group? The list goes on. There are many methods of analyzing one-sample relationships, and in our package we have implemented three.</p>
<div id="correlation" class="section level2">
<h2>Correlation</h2>
<p>While correlation is not an excellent source of inference, since it is inherently a feature of the dataset collected, sometimes it is important to know when variables are correlated. In the base R package, there are a few functions to calculate correlation: <code>cor()</code>, <code>var()</code>, <code>cov()</code>, and <code>cov2cor()</code>. Our function, <code>correlate()</code>, computes the correlation matrix between an arbitrary number of variables, and optionally also does this within a stratification variable. This is the real advantage of <code>correlate()</code>, since in base R we would have to manually subset the data into each stratum. If we want to examine the correlation between sex and diabetes, (and then stratify by race), we get</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Base R - returns only one number!
<span class="kw">cor</span>(mri$male, mri$diabetes)</code></pre></div>
<pre><code>## [1] 0.1200211</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## uwIntroStats version
<span class="kw">correlate</span>(mri$male, mri$diabetes)</code></pre></div>
<pre><code>## Tabled correlation statistics by strata
## Call:
##       correlate(mri$male, mri$diabetes) 
##      Method:  Pearson 
##      Data  :  Pairwise Complete 
##             - NaN denotes strata with no observations
##             - NA arises from missing data
## 
## ##### ALL DATA
##    ##  Estimated Correlation Coefficients 
##                    mri$male:  mri$diabetes: 
##     mri$male:  1.0000         0.1200        
## mri$diabetes:  0.1200         1.0000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Stratify on race
<span class="kw">correlate</span>(mri$male, mri$diabetes, <span class="dt">strata =</span> mri$race)</code></pre></div>
<pre><code>## Tabled correlation statistics by strata
## Call:
##       correlate(mri$male, mri$diabetes, strata = mri$race) 
##      Method:  Pearson 
##      Data  :  Pairwise Complete 
##             - NaN denotes strata with no observations
##             - NA arises from missing data
## 
## ##### Stratum   1 
##    ##  Estimated Correlation Coefficients 
##                    mri$male:  mri$diabetes: 
##     mri$male:  1.0000         0.0941        
## mri$diabetes:  0.0941         1.0000        
## 
## ##### Stratum   2 
##    ##  Estimated Correlation Coefficients 
##                    mri$male:  mri$diabetes: 
##     mri$male:  1.0000         0.2122        
## mri$diabetes:  0.2122         1.0000        
## 
## ##### Stratum   3 
##    ##  Estimated Correlation Coefficients 
##                    mri$male:  mri$diabetes: 
##     mri$male:  1.0000         0.1155        
## mri$diabetes:  0.1155         1.0000        
## 
## ##### Stratum   4 
##    ##  Estimated Correlation Coefficients 
##                    mri$male:  mri$diabetes: 
##     mri$male:  1.0000         0.3162        
## mri$diabetes:  0.3162         1.0000        
## 
## ##### ALL DATA
##    ##  Estimated Correlation Coefficients 
##                    mri$male:  mri$diabetes: 
##     mri$male:  1.0000         0.1200        
## mri$diabetes:  0.1200         1.0000</code></pre>
<p>Our function takes the pain out of calculating multiple correlations within stratum variables. We also return a correlation matrix rather than a single number, which allows the user to go straight to a covariance matrix by squaring. We also allow calculation of Spearman or Pearson (default) correlation.</p>
</div>
<div id="point-estimates-and-inference" class="section level2">
<h2>Point Estimates and Inference</h2>
<p>As mentioned above, since correlation is a function of the data gathered, we usually need other methods for our inference. One of the most common tests is the t-test, since we are often interested in the mean and making comparisons between means. Perhaps less common are the Wilcoxon and Mann-Whitney, which use the ``rank’’ of the variables compared.</p>
<div id="t-tests" class="section level3">
<h3>T-tests</h3>
<p>In the base R package, the <code>t.test()</code> function performs a t-test as you would expect. Our function <code>ttest()</code> improves on this by allowing stratification, calculation of the geometric mean, allowing for presuming unequal variances between samples, and making a cleaner output. For example, a t-test of whether the mean of the <code>ldl</code> variable is equal to 125 yields, in base R and <code>uwIntroStats</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## base R
<span class="kw">t.test</span>(mri$ldl, <span class="dt">mu =</span> <span class="dv">125</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  mri$ldl
## t = 0.64326, df = 724, p-value = 0.5203
## alternative hypothesis: true mean is not equal to 125
## 95 percent confidence interval:
##  123.3527 128.2528
## sample estimates:
## mean of x 
##  125.8028</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## uwIntroStats
<span class="kw">ttest</span>(mri$ldl, <span class="dt">null.hypoth =</span> <span class="dv">125</span>)</code></pre></div>
<pre><code>## 
## Call:
## ttest(var1 = mri$ldl, null.hypoth = 125)
## 
## One-sample t-test :
##  
## Summary:
##  Variable Obs Missing Mean Std. Err. Std. Dev.     95% CI
##   mri$ldl 735      10  126      1.25      33.6 [123, 128]
## 
##  Ho:  mean = 125 ; 
##  Ha:  mean != 125 
##  t = 0.6433 , df = 724 
##  Pr(|T| &gt; t) =  0.520256</code></pre>
<p>If instead we wanted a two-sample t-test of whether the difference in mean LDL between males and females were zero, we would get</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## base R
<span class="kw">t.test</span>(mri$ldl[mri$male ==<span class="st"> </span><span class="dv">0</span>], mri$ldl[mri$male ==<span class="st"> </span><span class="dv">1</span>])</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  mri$ldl[mri$male == 0] and mri$ldl[mri$male == 1]
## t = 4.1938, df = 721.23, p-value = 3.084e-05
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##   5.502342 15.188221
## sample estimates:
## mean of x mean of y 
##  130.9397  120.5944</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## uwIntroStats
<span class="kw">ttest</span>(mri$ldl, <span class="dt">by =</span> mri$male)</code></pre></div>
<pre><code>## 
## Call:
## ttest(var1 = mri$ldl, by = mri$male)
## 
## Two-sample t-test allowing for unequal variances :
##  
## Summary:
##           Group Obs Missing  Mean Std. Err. Std. Dev.         95% CI
##    mri$male = 1 369       4 130.9      1.79      34.3 [127.4, 134.5]
##    mri$male = 0 366       6 120.6      1.69      32.1 [117.3, 123.9]
##      Difference 735      10  10.3      2.47      &lt;NA&gt;    [5.5, 15.2]
## 
##  Ho: difference in  means = 0 ; 
##  Ha: difference in  means != 0 
##  t = 4.194 , df = 721 
##  Pr(|T| &gt; t) =  3.08428e-05</code></pre>
<p>Note that in our package, the default is to presume unequal variances between samples, which the authors believe to usually be the correct course. Also, we don’t have to subset the data manually. We also run two-sided tests by default, but others can be specified.</p>
</div>
<div id="generic-inference" class="section level3">
<h3>Generic Inference</h3>
<p>Until now, all of the methods in this section work on multiple samples. However, if we want to produce point estimates, interval estimates, and p-values for an arbitrary functional (mean, geometric mean, proportion, median, quantile, odds) of a variable, we can use the <code>oneSample()</code> function. Base R does not have a function which performs this general inference all in one spot. In the following tests, we will run one- and two-sample t-tests and an exact binomial test, all on the LDL variable. The t-tests run by <code>oneSample()</code> are an alternative to <code>ttest()</code> as described above. The output is not as verbose, but all of the information is the same:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## base R
<span class="kw">t.test</span>(mri$ldl, <span class="dt">mu =</span> <span class="dv">125</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  mri$ldl
## t = 0.64326, df = 724, p-value = 0.5203
## alternative hypothesis: true mean is not equal to 125
## 95 percent confidence interval:
##  123.3527 128.2528
## sample estimates:
## mean of x 
##  125.8028</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## ttest
<span class="kw">ttest</span>(mri$ldl, <span class="dt">null.hypoth =</span> <span class="dv">125</span>)</code></pre></div>
<pre><code>## 
## Call:
## ttest(var1 = mri$ldl, null.hypoth = 125)
## 
## One-sample t-test :
##  
## Summary:
##  Variable Obs Missing Mean Std. Err. Std. Dev.     95% CI
##   mri$ldl 735      10  126      1.25      33.6 [123, 128]
## 
##  Ho:  mean = 125 ; 
##  Ha:  mean != 125 
##  t = 0.6433 , df = 724 
##  Pr(|T| &gt; t) =  0.520256</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## oneSample
<span class="kw">oneSample</span>(<span class="st">&quot;mean&quot;</span>, mri$ldl, <span class="dt">null.hypothesis =</span> <span class="dv">125</span>)</code></pre></div>
<pre><code>## Hypothesis test of two-sided alternative that Mean &lt;&gt; 125 
## Method: One sample t test 
## 10 observations deleted due to missing values
##     n       Mean    95% CIlo  95% CIhi  Null Hyp   P two   
##    725      125.8     123.4     128.3     125.0     0.5203</code></pre>
<p>However, the true flexibility of the <code>oneSample()</code> function comes into play when we ask about different functionals. If we want inference on the geometric mean (which might make sense since LDL is a biological variable that may exhibit extreme values due to illness), in base R or with <code>ttest()</code> we have to logarithmically transform our variable and then run the t-test. With <code>oneSample()</code>, we simply run on <code>&quot;geometric mean&quot;</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## base R
<span class="kw">t.test</span>(<span class="kw">log</span>(mri$ldl), <span class="dt">mu =</span> <span class="kw">log</span>(<span class="dv">125</span>))</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  log(mri$ldl)
## t = -3.0054, df = 724, p-value = 0.002744
## alternative hypothesis: true mean is not equal to 4.828314
## 95 percent confidence interval:
##  4.774290 4.816983
## sample estimates:
## mean of x 
##  4.795636</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## ttest
<span class="kw">ttest</span>(<span class="kw">log</span>(mri$ldl), <span class="dt">null.hypoth =</span> <span class="kw">log</span>(<span class="dv">125</span>))</code></pre></div>
<pre><code>## 
## Call:
## ttest(var1 = log(mri$ldl), null.hypoth = log(125))
## 
## One-sample t-test :
##  
## Summary:
##      Variable Obs Missing Mean Std. Err. Std. Dev.       95% CI
##  log(mri$ldl) 735      10  4.8    0.0109     0.293 [4.77, 4.82]
## 
##  Ho:  mean = 4.8283137373023 ; 
##  Ha:  mean != 4.8283137373023 
##  t = -3.005 , df = 724 
##  Pr(|T| &gt; t) =  0.00274401</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## oneSample
<span class="kw">oneSample</span>(<span class="st">&quot;geometric mean&quot;</span>, mri$ldl, <span class="dt">null.hypothesis =</span> <span class="dv">125</span>)</code></pre></div>
<pre><code>## Hypothesis test of two-sided alternative that GeomMn &lt;&gt; 125 
## Method: One sample t test on log transformed data 
## 10 observations deleted due to missing values
##     n      GeomMn   95% CIlo  95% CIhi  Null Hyp   P two    
##    725      121.0     118.4     123.6     125.0    2.744e-03</code></pre>
<p>We can also compute an exact binomial test of the proportion of LDL values that are greater than 128:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## base R
<span class="kw">binom.test</span>(<span class="kw">sum</span>(mri$ldl &gt;<span class="st"> </span><span class="dv">128</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>), <span class="dt">n =</span> <span class="kw">sum</span>(!<span class="kw">is.na</span>(mri$ldl)))</code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  sum(mri$ldl &gt; 128, na.rm = TRUE) and sum(!is.na(mri$ldl))
## number of successes = 336, number of trials = 725, p-value =
## 0.05338
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.4266728 0.5005223
## sample estimates:
## probability of success 
##              0.4634483</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## oneSample
<span class="kw">oneSample</span>(<span class="st">&quot;prop&quot;</span>, mri$ldl &gt;<span class="st"> </span><span class="dv">128</span>, <span class="dt">null.hypothesis =</span> <span class="fl">0.5</span>)</code></pre></div>
<pre><code>## Hypothesis test of two-sided alternative that Pr(Event) &lt;&gt; 0.5 
## Method: One sample inference for binomial proportions using exact distribution (LR ordering) 
## 10 observations deleted due to missing values
##      n     Pr(Event) 95% CIlo  95% CIhi  Null Hyp    P two  
##    725       0.4634    0.4267    0.5005    0.5000   0.05338</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">oneSample</span>(<span class="st">&quot;prop&quot;</span>, mri$ldl, <span class="dt">above =</span> <span class="dv">128</span>, <span class="dt">null.hypothesis =</span> <span class="fl">0.5</span>)</code></pre></div>
<pre><code>## Hypothesis test of two-sided alternative that Pr&gt;128 &lt;&gt; 0.5 
## Method: One sample inference for binomial proportions using exact distribution (LR ordering) 
## 10 observations deleted due to missing values
##     n      Pr&gt;128   95% CIlo  95% CIhi  Null Hyp   P two   
##    725      0.4634    0.4267    0.5005    0.5000   0.05338</code></pre>
<p>The syntax for <code>oneSample()</code> is much more intuitive; we simply enter that we want to test a proportion, and then give the logical value to test or specify the threshold. Also, rather than having to count successes, the total, and dealing with missing values by hand, we can let <code>oneSample()</code> handle everything for us and give output that is clearer to read.</p>
</div>
<div id="wilcoxon-and-mann-whitney" class="section level3">
<h3>Wilcoxon and Mann-Whitney</h3>
<p>The most similar function between our package and the base R package is the function to perform Wilcoxon Signed Rank tests and Mann-Whitney-Wilcoxon Ranked Sum tests. Our function, <code>wilcoxon()</code>, adds formatting and variances, and prints the z-score and p-value in addition to the test statistic and p-value. Otherwise, the functions are the same, though we follow our usual syntax of Y followed by X. For example, if we want to test diseased versus healthy (in a made-up dataset), we can get</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## create the data
cf &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1153</span>, <span class="dv">1132</span>, <span class="dv">1165</span>, <span class="dv">1460</span>, <span class="dv">1162</span>, <span class="dv">1493</span>, <span class="dv">1358</span>, <span class="dv">1453</span>, <span class="dv">1185</span>, <span class="dv">1824</span>, <span class="dv">1793</span>, <span class="dv">1930</span>, <span class="dv">2075</span>)
healthy &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">996</span>, <span class="dv">1080</span>, <span class="dv">1182</span>, <span class="dv">1452</span>, <span class="dv">1634</span>, <span class="dv">1619</span>, <span class="dv">1140</span>, <span class="dv">1123</span>, <span class="dv">1113</span>, <span class="dv">1463</span>, <span class="dv">1632</span>, <span class="dv">1614</span>, <span class="dv">1836</span>)

## base R
<span class="kw">wilcox.test</span>(healthy, cf, <span class="dt">paired =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test
## 
## data:  healthy and cf
## V = 20, p-value = 0.08032
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## uwIntroStats
<span class="kw">wilcoxon</span>(cf, healthy, <span class="dt">paired =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test 
##          obs sum ranks expected
## positive  10        71     45.5
## negative   3        20     45.5
## zero       0         0      0.0
## all       13        91     91.0
##                             
## unadjusted variance   204.75
## adjustment for ties     0.00
## adjustment for zeroes   0.00
## adjusted variance     204.75
##                     H0 Ha       
## Hypothesized Median 0  two.sided
##   Test Statistic p-value 
## V 71             0.080322
## Z 1.7821         0.037368</code></pre>
<p>Note that in the output of <code>wilcoxon()}</code> we have displayed the data calculated by the signed rank test, and given both the test statistic (V) and the z-score (Z).</p>
</div>
</div>
</div>
<div id="regression" class="section level1">
<h1>Regression</h1>
<p>Regression is one of the most widely used and easily understood methods of statistical analysis. The base R package has many different functions to perform regression: <code>lm()</code> for linear regression, <code>glm()</code> for generalized linear regression (which allows you to perform logistic regression, for example), <code>coxph()</code> for proportional hazards regression, and <code>geeglm()</code> as (one) method for correlated data regression. Each function has slightly different options, and remembering all of these is a chore. Part of the motivation for <code>regress()</code> is to alleviate this problem. This function provides one interface through which all types of regression can be performed. We also print the output from the regression in a much more understandable manner. Also, as we did in <code>ttest()</code>, we allow the user to calculate and use robust standard error estimates (using the Huber-White sandwich estimator), which adds flexibility. The <code>regress()</code> function does all of this while keeping the same formula syntax as its predecessors: <code>y~x1+x2*x3</code> still produces a linear model with coefficients for <code>x1</code>, <code>x2</code>, <code>x3</code>, and the interaction between <code>x2</code> and <code>x3</code>. The next four subsections deal with aspects of <code>regress()</code> in more detail.</p>
<div id="basics-of-regress" class="section level2">
<h2>Basics of <code>regress()</code></h2>
<p>The minimum we need to enter into <code>regress()</code> is a functional, a formula, and a dataset. A functional takes an object and returns a value; for instance, the mean is a functional because it takes a distribution and returns the mean. The allowed functionals are displayed in <a href="#fnctl">Table 2</a>. Once we have a functional in mind (for now we choose the mean), we need to decide if we want to use robust standard error estimates. The default in <code>regress()</code> is to use these estimates, since we usually believe that the variances are not truly equal between groups compared in a regression analysis. The base R functions do presume equal variances between groups, which can lead to conservative (or anti-conservative) inference in some situations. The last change we have made to the usual regression output is displaying F-statistics rather than t-statistics for the test of each variable. We decided to use the F-distribution to make our results line up more easily with classical ANOVA tables. In most cases, the F-statistic is simply the square of the t-statistic. The inference is the same. To see <code>regress()</code> in action, consider testing the association between age and atrophy. The syntax for this computation is the same as that for any of the previous commands you might have used.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## base R
<span class="kw">summary</span>(<span class="kw">lm</span>(atrophy ~<span class="st"> </span>age, <span class="dt">data =</span> mri))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = atrophy ~ age, data = mri)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -36.870  -8.589  -0.870   7.666  51.203 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -16.06213    6.25619  -2.567   0.0104 *  
## age           0.69798    0.08368   8.341 3.64e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 12.36 on 733 degrees of freedom
## Multiple R-squared:  0.08669,    Adjusted R-squared:  0.08545 
## F-statistic: 69.58 on 1 and 733 DF,  p-value: 3.635e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## uwIntroStats
<span class="kw">regress</span>(<span class="st">&quot;mean&quot;</span>, atrophy ~<span class="st"> </span>age, <span class="dt">data =</span> mri)</code></pre></div>
<pre><code>## 
## Call:
## regress(fnctl = &quot;mean&quot;, formula = atrophy ~ age, data = mri)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -36.870  -8.589  -0.870   7.666  51.203 
## 
## Coefficients:
##                  Estimate  Naive SE  Robust SE    95%L      95%H     
## [1] Intercept     -16.06     6.256     6.701       -29.22    -2.907  
## [2] age            0.6980   0.08368   0.09002       0.5213    0.8747 
##                     F stat    df Pr(&gt;F)   
## [1] Intercept            5.75 1    0.0168 
## [2] age                 60.12 1  &lt; 0.00005
## 
## Residual standard error: 12.36 on 733 degrees of freedom
## Multiple R-squared:  0.08669,    Adjusted R-squared:  0.08545 
## F-statistic: 60.12 on 1 and 733 DF,  p-value: 2.988e-14</code></pre>
<p>Note that by default, our output is printed in a table, rather than having to call <code>summary.lm()</code>. The inference on the individual coefficients is different because we have used the F-distribution and are using robust standard error estimates, but we get approximately the same p-values. Also, the overall F-statistic is different in our version because we are using the robust standard error estimates. The numbers next to the coefficients tell us which to specify in any post-testing commands we run (see section 8).</p>
</div>
<div id="regression-on-different-functionals" class="section level2">
<h2>Regression on different functionals</h2>
<p>As mentioned above, part of the motivation for the <code>regress()</code> function was to have all types of regression in one function. Thus the other functionals we allow, and their corresponding commands in base R, are displayed in <a href="#fnctl">Table 2</a>. Note that we only display the options which lead to a certain type of regression, not the rest of the syntax.</p>
<p><a id="fnctl"></a></p>
<table>
<thead>
<tr class="header">
<th align="left">Functional</th>
<th align="left">Type of Regression</th>
<th align="left">Previous command (package)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>&quot;mean&quot;</code></td>
<td align="left">Linear Regression</td>
<td align="left"><code>lm()</code> (<code>stats</code> - base R)</td>
</tr>
<tr class="even">
<td align="left"><code>&quot;geometric mean&quot;</code></td>
<td align="left">Linear Regression on logarithmically transformed Y</td>
<td align="left"><code>lm()</code>, with Y log transformed (<code>stats</code> - base R)</td>
</tr>
<tr class="odd">
<td align="left"><code>&quot;odds&quot;</code></td>
<td align="left">Logistic Regression</td>
<td align="left"><code>glm(family = binomial)</code> (<code>stats</code> - base R)</td>
</tr>
<tr class="even">
<td align="left"><code>&quot;rate&quot;</code></td>
<td align="left">Poisson Regression</td>
<td align="left"><code>glm(family = poisson)</code> (<code>stats</code> - base R)</td>
</tr>
<tr class="odd">
<td align="left"><code>&quot;hazard&quot;</code></td>
<td align="left">Proportional Hazards Regression</td>
<td align="left"><code>coxph()</code> (<code>survival</code>)</td>
</tr>
</tbody>
</table>
<p>If we enter a functional other than the mean, there is usually a transformation that needs to be applied to the data within the <code>regress()</code> function. In all of the cases listed in <a href="#fnctl">Table 2</a>, the transformation is the logarithm. For example, sometimes the logistic regression model is taught as having a “log link”, or the poisson regression model is taught as having the “logit link”. These both refer to the function of the parameter having logarithms, so that the model is linear in the coefficients on the predictors. Therefore, in each case, we back-transform - by using the <code>exp(x)</code> function, which is equivalent to <span class="math inline">\(e^x\)</span> - the output of the regression by default, but also display the output that has not been back-transformed. This allows the user to easily see the results in the correct units, while also retaining the ability to compare with other software or handle the un-exponentiated results. If we want to examine the association between LDL and age, but want to use the geometric mean, we get</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">regress</span>(<span class="st">&quot;geom&quot;</span>, ldl ~<span class="st"> </span>age, <span class="dt">data =</span> mri)</code></pre></div>
<pre><code>## ( 10  cases deleted due to missing values)
## 
## 
## Call:
## regress(fnctl = &quot;geom&quot;, formula = ldl ~ age, data = mri)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.39512 -0.17020  0.03572  0.19342  0.70883 
## 
## Coefficients:
## 
## Raw Model:
##                  Estimate   Naive SE   Robust SE        F stat    df
## [1] Intercept       4.876     0.1494     0.1437           1150.70 1 
## [2] age          -1.077e-03  1.999e-03  1.932e-03            0.31 1 
##                  Pr(&gt;F)   
## [1] Intercept    &lt; 0.00005
## [2] age            0.5771 
## 
## Transformed Model:
##                  e(Est)    e(95%L)   e(95%H)         F stat    df
## [1] Intercept      131.1     98.87     173.8           1150.70 1 
## [2] age            0.9989    0.9951    1.003              0.31 1 
##                  Pr(&gt;F)   
## [1] Intercept    &lt; 0.00005
## [2] age            0.5771 
## 
## Residual standard error: 0.2929 on 723 degrees of freedom
##   (10 observations deleted due to missingness)
## Multiple R-squared:  0.0004018,  Adjusted R-squared:  -0.0009808 
## F-statistic: 0.3112 on 1 and 723 DF,  p-value: 0.5771</code></pre>
<p>In the transformed table, we do not display the standard error estimates, since they do not scale appropriately with the transformation. We could compare this to the base R function by log-transforming the <code>ldl</code> variable, running <code>lm()</code>, and back-transforming the results ourselves:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## transform the ldl variable
logldl &lt;-<span class="st"> </span><span class="kw">log</span>(mri$ldl)
## create the model
mod &lt;-<span class="st"> </span><span class="kw">lm</span>(logldl ~<span class="st"> </span>age, <span class="dt">data =</span> mri)
## view the coefficients (untransformed)
<span class="kw">summary</span>(mod)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = logldl ~ age, data = mri)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.39512 -0.17020  0.03572  0.19342  0.70883 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.875983   0.149445  32.627   &lt;2e-16 ***
## age         -0.001077   0.001999  -0.539     0.59    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.2929 on 723 degrees of freedom
##   (10 observations deleted due to missingness)
## Multiple R-squared:  0.0004018,  Adjusted R-squared:  -0.0009808 
## F-statistic: 0.2906 on 1 and 723 DF,  p-value: 0.59</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## back-transform the coefficients and CI
mod.sum &lt;-<span class="st"> </span><span class="kw">summary</span>(mod)
## this gives the coefficients
<span class="kw">exp</span>(mod.sum$coefficients[,<span class="dv">1</span>])</code></pre></div>
<pre><code>## (Intercept)         age 
## 131.1029250   0.9989231</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## this gives the CI
<span class="kw">exp</span>(mod.sum$coefficients[,<span class="dv">1</span>] -<span class="st"> </span><span class="fl">1.96</span>*mod.sum$coefficients[,<span class="dv">2</span>])</code></pre></div>
<pre><code>## (Intercept)         age 
##  97.8143254   0.9950173</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(mod.sum$coefficients[,<span class="dv">1</span>] +<span class="st"> </span><span class="fl">1.96</span>*mod.sum$coefficients[,<span class="dv">2</span>])</code></pre></div>
<pre><code>## (Intercept)         age 
##  175.720447    1.002844</code></pre>
<p>First, this is much more work, and requires thought for how to calculate the confidence interval - should we use the convenient approximation of 1.96, or should we use the <code>qnorm()</code> function? Second, we again lose the option of using robust standard error estimates. To use these, we would have to manually code a few more lines, which would increase the likelihood of a small mistake in the code. Our <code>regress()</code> function pulls all of this together in a simple format, leading to much fewer mistakes.</p>
</div>
<div id="correlated-data-regression" class="section level2">
<h2>Correlated data regression</h2>
<p>This section does not serve as a primer for when to account for correlated data in your regression model; rather, if you know that you have correlated data, it gives you a method to accounting for it. We will not use the <code>mri</code> data for this example. Instead, we will use the <code>salary</code> data, available as a text file <a href="http://www.emersonstatistics.com/datasets/salary.txt">“salary.txt”</a>. The documentation for this file is at <a href="http://www.emersonstatistics.com/datasets/salary.doc">“salary.doc”</a>. These data deal with salaries at the University of Washington, and have multiple records on most participants. In fact, for any current faculty member in 1995 who had been employed by the university for more than one year, there were yearly records dating back to when the faculty member was hired. Thus by nature these data are correlated - in the simplest sense, we expect that the salary for a single faculty member will rise (or at least stay constant) each year. Therefore, we need to use the correlated data apparatus built into <code>regress()</code>. This functionality uses the <code>geeglm()</code> function from the package <code>geepack</code>, but frames the output consistently with the rest of the <code>regress()</code> options and uses the same syntax.</p>
<p>First, let’s create the data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">salary &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;http://www.emersonstatistics.com/datasets/salary.txt&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>, <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)
salary$female &lt;-<span class="st"> </span><span class="kw">ifelse</span>(salary$sex ==<span class="st"> &quot;F&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</code></pre></div>
<p>This code makes sure that the header in the text file is read as variable names, and that the string variables do not get converted to factor variables. We also create an indicator variable of whether the person is female or not. Next, suppose we are interested in the mean salary for females as opposed to males. Since raises are usually calculated as a percentage of current salary, and starting salaries can vary by year, we decide that the year in which a person started is important in determining their salary. For a more in-depth look at this thought process, see any document on determining potential confounding variables (for one, see parts of <a href="http://www.emersonstatistics.com/GeneralMaterials/analysis.pdf">“Organizing Your Approach to a Data Analysis”</a>). By adding the <code>id</code> argument to <code>regress()</code>, we can account for the correlated data. In the <code>salary</code> dataset, the ID column is named <code>id</code>, and thus we have:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## adjusting for correlated data
<span class="kw">regress</span>(<span class="st">&quot;mean&quot;</span>,salary ~<span class="st"> </span>female*year, <span class="dt">id =</span> id, <span class="dt">data =</span> salary)</code></pre></div>
<pre><code>## 
## Call:
## regress(fnctl = &quot;mean&quot;, formula = salary ~ female * year, data = salary, 
##     id = id)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3727.9   -907.4   -230.0    719.2   7605.5  
## 
## Coefficients:
##                    Estimate  Std Err   95%L         95%H         Wald     
## [1] Intercept       -17417     283.6    -17973       -16861        3771.66
## [2] female            4102     528.7      3065         5138          60.20
## [3] year             255.5     3.536     248.6        262.5        5222.05
## [4] female:year     -57.88     6.370    -70.36       -45.39          82.56
##                    df Pr(&gt;|W|) 
## [1] Intercept      1  &lt; 0.00005
## [2] female         1  &lt; 0.00005
## [3] year           1  &lt; 0.00005
## [4] female:year    1  &lt; 0.00005
## 
##  Estimated Scale Parameters: 
##             Estimate  Std.err
## (Intercept)  2024610 77997.57
## 
##  Correlation: Structure =  independence 
## 
##  Number of Clusters:  1597 
## 
##  Maximum Cluster Size:  20</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## without adjusting
<span class="kw">regress</span>(<span class="st">&quot;mean&quot;</span>, salary ~<span class="st"> </span>female*year, <span class="dt">data =</span> salary)</code></pre></div>
<pre><code>## 
## Call:
## regress(fnctl = &quot;mean&quot;, formula = salary ~ female * year, data = salary)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3727.9  -907.4  -230.0   719.2  7605.5 
## 
## Coefficients:
##                    Estimate  Naive SE  Robust SE    95%L      95%H     
## [1] Intercept       -17417     176.5     167.6       -17745    -17088  
## [2] female            4102     420.7     299.5         3515      4689  
## [3] year             255.5     2.021     2.005        251.6     259.5  
## [4] female:year     -57.88     4.757     3.541       -64.82    -50.94  
##                       F stat    df Pr(&gt;F)   
## [1] Intercept          10802.86 1  &lt; 0.00005
## [2] female               187.59 1  &lt; 0.00005
## [3] year               16235.87 1  &lt; 0.00005
## [4] female:year          267.10 1  &lt; 0.00005
## 
## Residual standard error: 1423 on 19788 degrees of freedom
## Multiple R-squared:  0.487,  Adjusted R-squared:  0.4869 
## F-statistic:  7166 on 3 and 19788 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Notice that we get some extra information in the output where we adjusted - we see that there are 1597 unique faculty members in the data, and that the longest we have data for is 20 years. Therefore treating the data as independent, like we do in the second call to <code>regress()</code>, will lead to invalid standard error estimates and therefore invalid confidence intervals and inference.</p>
</div>
<div id="multiple-partial-f-tests" class="section level2">
<h2>Multiple-partial F-tests</h2>
<p>The major added functionality that <code>regress()</code> brings to the table is the ability to perform multiple-partial F-tests. Some of these are done automatically when certain dummy variables, polynomial variables, or linear splines are entered - if created in a manner similar to our functions above. Others must be specified by the user, using a special function called <code>U()</code>.</p>
<p>As an example of the automatic multiple-partial F-test calculation, let’s say we run a regression of atrophy on race, modeled as dummy variables. Recall from our work above that the dummy variables created by <code>race</code> have three levels, and each is in reference to the level coded as <code>white</code>. When we run this regression,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">regress</span>(<span class="st">&quot;mean&quot;</span>, atrophy ~<span class="st"> </span><span class="kw">dummy</span>(race), <span class="dt">data =</span> mri)</code></pre></div>
<pre><code>## 
## Call:
## regress(fnctl = &quot;mean&quot;, formula = atrophy ~ dummy(race), data = mri)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -31.243  -9.243  -0.462   7.757  47.757 
## 
## Coefficients:
##                    Estimate  Naive SE  Robust SE    95%L      95%H     
## [1] Intercept        36.24     0.5408    0.5438       35.18     37.31  
##     dummy(race)                                                        
## [2]    race.2       -1.781     1.379     1.334       -4.401     0.8381 
## [3]    race.3        0.2676    1.962     1.904       -3.470     4.005  
## [4]    race.4       -1.493     3.772     4.422       -10.17     7.189  
##                       F stat    df Pr(&gt;F)   
## [1] Intercept           4441.94 1  &lt; 0.00005
##     dummy(race)            0.65 3    0.5832 
## [2]    race.2              1.78 1    0.1823 
## [3]    race.3              0.02 1    0.8882 
## [4]    race.4              0.11 1    0.7357 
## 
##  Dummy terms calculated from race, reference = 1 
## 
## Residual standard error: 12.93 on 731 degrees of freedom
## Multiple R-squared:  0.002535,   Adjusted R-squared:  -0.001559 
## F-statistic: 0.6499 on 3 and 731 DF,  p-value: 0.5832</code></pre>
<p>notice that the coefficients for each dummy variable are presented in the usual way (though it is up to you to remember what <code>race.2</code> stands for). However, there is a new line above all of the dummy variable coefficients. First we see that this line does not get a coefficient number - that’s because this line is only for the multiple partial F-test. Also, note that the regression coefficients are indented beneath it. This denotes that these dummy variables all belong to the same original variable (race). The test has three degrees of freedom, because there are three dummy variables that it is simultaneously testing. Recall that in an F-test, and in the t-test of normal linear regression in <code>lm()</code>, the null hypothesis for each of the p-values presented in the regression table is that the regression coefficient is equal to zero. The multiple partial F-test simulataneously tests that <em>all three</em> coefficients are equal to zero. It allows us to declare that there is no significant association between race and atrophy at the 0.05 level, since we have tested all race variables simultaneoudly and returned a p-value of 0.58.</p>
<p>We also see that after the coefficients table, <code>regress()</code> tells us how the dummy variables were computed.</p>
<p>Now for the user-defined multiple-partial F-tests, we need to be a bit careful. If entered in a call to <code>regress()</code>, the <code>U()</code> function takes in a formula, which can be named, and returns the specified multiple-partial F-test to the regression output. It also adds any new variables to the regression model. As an example of the <code>U()</code> function, if we wanted to add age and male to our model, and we wanted to have a multiple-partial F-test of these two variables, we could add</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">U</span>(~age +<span class="st"> </span>male)</code></pre></div>
<p>to the model above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">regress</span>(<span class="st">&quot;mean&quot;</span>, atrophy ~<span class="st"> </span><span class="kw">dummy</span>(race) +<span class="st"> </span><span class="kw">U</span>(~age +<span class="st"> </span>male), <span class="dt">data =</span> mri)</code></pre></div>
<pre><code>## 
## Call:
## regress(fnctl = &quot;mean&quot;, formula = atrophy ~ dummy(race) + U(~age + 
##     male), data = mri)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -34.120  -8.331  -0.434   7.325  53.915 
## 
## Coefficients:
##                      Estimate  Naive SE  Robust SE    95%L      95%H     
## [1] Intercept         -17.87     6.079     6.589       -30.81    -4.933  
##     dummy(race)                                                          
## [2]    race.2         -2.109     1.280     1.246       -4.554     0.3370 
## [3]    race.3          0.2664    1.822     1.780       -3.228     3.761  
## [4]    race.4         -2.812     3.503     3.812       -10.30     4.671  
##     U(age + male)                                                        
## [5]   age              0.6866   0.08134   0.08836       0.5132    0.8601 
## [6]   male             5.988     0.8867    0.8895       4.242     7.734  
##                         F stat    df Pr(&gt;F)   
## [1] Intercept                7.35 1    0.0068 
##     dummy(race)              1.14 3    0.3315 
## [2]    race.2                2.87 1    0.0909 
## [3]    race.3                0.02 1    0.8810 
## [4]    race.4                0.54 1    0.4609 
##     U(age + male)           52.66 2  &lt; 0.00005
## [5]   age                   60.38 1  &lt; 0.00005
## [6]   male                  45.32 1  &lt; 0.00005
## 
##  Dummy terms calculated from race, reference = 1 
## 
## Residual standard error: 12 on 729 degrees of freedom
## Multiple R-squared:  0.1439, Adjusted R-squared:  0.138 
## F-statistic: 21.32 on 5 and 729 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Note that again the multiple-partial F-test line is not a coefficient, but that the variables specified in the <code>U()</code> forumla are part of the regression model. If we wanted to make this output a bit more readable, we could give the second multiple-partial F-test a name by adding <code>testnm =</code> within our call to <code>U()</code>, before the formula.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">regress</span>(<span class="st">&quot;mean&quot;</span>, atrophy ~<span class="st"> </span><span class="kw">dummy</span>(race) +<span class="st"> </span><span class="kw">U</span>(<span class="dt">ma =</span> ~age +<span class="st"> </span>male), <span class="dt">data =</span> mri)</code></pre></div>
<pre><code>## 
## Call:
## regress(fnctl = &quot;mean&quot;, formula = atrophy ~ dummy(race) + U(ma = ~age + 
##     male), data = mri)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -34.120  -8.331  -0.434   7.325  53.915 
## 
## Coefficients:
##                    Estimate  Naive SE  Robust SE    95%L      95%H     
## [1] Intercept       -17.87     6.079     6.589       -30.81    -4.933  
##     dummy(race)                                                        
## [2]    race.2       -2.109     1.280     1.246       -4.554     0.3370 
## [3]    race.3        0.2664    1.822     1.780       -3.228     3.761  
## [4]    race.4       -2.812     3.503     3.812       -10.30     4.671  
##     ma                                                                 
## [5]   age            0.6866   0.08134   0.08836       0.5132    0.8601 
## [6]   male           5.988     0.8867    0.8895       4.242     7.734  
##                       F stat    df Pr(&gt;F)   
## [1] Intercept              7.35 1    0.0068 
##     dummy(race)            1.14 3    0.3315 
## [2]    race.2              2.87 1    0.0909 
## [3]    race.3              0.02 1    0.8810 
## [4]    race.4              0.54 1    0.4609 
##     ma                    52.66 2  &lt; 0.00005
## [5]   age                 60.38 1  &lt; 0.00005
## [6]   male                45.32 1  &lt; 0.00005
## 
##  Dummy terms calculated from race, reference = 1 
## 
## Residual standard error: 12 on 729 degrees of freedom
## Multiple R-squared:  0.1439, Adjusted R-squared:  0.138 
## F-statistic: 21.32 on 5 and 729 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Other than the new name, the output is exactly the same as our original call.</p>
</div>
</div>
<div id="post-estimation" class="section level1">
<h1>Post Estimation</h1>
<p>After we have created a regression model and run the test, sometimes we want to check parts of our model. Usually, this comes in the form of an ANOVA table testing whether a combination of our coefficients are simultaneously equal to zero. As we saw in the previous section, <code>regress()</code> allows us to run these types of commands within the regression call. However, to check these results - or to avoid using <code>U()</code> within a call to <code>regress()</code> - we can use post estimation commands.</p>
<p>Also, it is sometimes of interest to predict on a new data set. The object created by a call to <code>regress()</code> is like all other regression objects (from calls to <code>lm()</code>, <code>glm()</code>, etc) in that it allows predictions.</p>
<div id="linear-combinations-of-regression-coefficients" class="section level2">
<h2>Linear Combinations of Regression Coefficients</h2>
<p>A very useful function in STATA is the <code>lincom</code> function. This is a post-testing function which allows the user to specify a linear combination of the regression coefficients to simultaneously test. We have recreated this function in R, and it follows a similar syntax. Recall that the <code>regress()</code> function displays a number next to each coefficient in the coefficients table. These numbers refer to the position of each variable in the call to <code>lincom()</code>. The default null hypothesis is that the linear combination is equal to zero.</p>
<p>This function can take either a vector or a matrix determining the linear combination to test. To have a better idea of how this works, we provide an example. In the previous section, when we introduced multiple-partial F-tests, we ran a regression of atrophy on race (modeled as dummy variables), male, and age. We can perform the same test using <code>lincom()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## get the model
mod &lt;-<span class="st"> </span><span class="kw">regress</span>(<span class="st">&quot;mean&quot;</span>, atrophy ~<span class="st"> </span><span class="kw">dummy</span>(race) +<span class="st"> </span>age +<span class="st"> </span>male, <span class="dt">data =</span> mri)

## get the test of age and male
<span class="kw">lincom</span>(mod, <span class="dt">comb =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>))</code></pre></div>
<pre><code>## 
## H0: 1*age+1*male   =  0 
## Ha: 1*age+1*male  !=  0 
##    Estimate   Std. Err.           T Pr(T &gt; |t|)        95%L        95%H 
##      6.6744      0.8942      7.4645      1.0000      4.9190      8.4299</code></pre>
<p>This test gives us the same inference as before - that the probability of seeing this event is extrememly small if the null hypothesis is true. Now in some cases we might be interested in combinations that aren’t just the raw data. If we want, for example, twice the male coefficient, we can get this easily:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lincom</span>(mod, <span class="dt">comb =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>))</code></pre></div>
<pre><code>## 
## H0: 1*age+2*male   =  0 
## Ha: 1*age+2*male  !=  0 
##    Estimate   Std. Err.           T Pr(T &gt; |t|)        95%L        95%H 
##     12.6622      1.7814      7.1079      1.0000      9.1649     16.1596</code></pre>
</div>
<div id="prediction" class="section level2">
<h2>Prediction</h2>
<p>Prediction with a <code>uRegress</code> object (which is created by a call to <code>regress()</code>) follows the same syntax as prediction for any other regression object. Say we have split the mri data into a training and test set to learn our linear regression model on. First we set a seed, so that our random number generator will always start in the same place and we are guaranteed reproducible results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">47</span>)
samp &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(mri), <span class="kw">nrow</span>(mri)/<span class="dv">2</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)
mri.train &lt;-<span class="st"> </span>mri[samp, ]
mri.test &lt;-<span class="st"> </span>mri[-samp,]

modlm &lt;-<span class="st"> </span><span class="kw">lm</span>(atrophy ~<span class="st"> </span>age +<span class="st"> </span>male +<span class="st"> </span><span class="kw">dummy</span>(race), <span class="dt">data =</span> mri.train)
modreg &lt;-<span class="st"> </span><span class="kw">regress</span>(<span class="st">&quot;mean&quot;</span>, atrophy ~<span class="st"> </span>age +<span class="st"> </span>male +<span class="st"> </span><span class="kw">dummy</span>(race), <span class="dt">data =</span> mri.train)

predslm &lt;-<span class="st"> </span><span class="kw">predict</span>(modlm, <span class="dt">data =</span> mri.test)
predsreg &lt;-<span class="st"> </span><span class="kw">predict</span>(modreg, <span class="dt">data =</span> mri.test)

<span class="kw">head</span>(predslm, <span class="dt">n =</span> <span class="dv">5</span>)</code></pre></div>
<pre><code>##      719      275      559      603      420 
## 34.67201 46.44437 31.99498 38.41326 38.41326</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(predsreg, <span class="dt">n =</span> <span class="dv">5</span>)</code></pre></div>
<pre><code>##      719      275      559      603      420 
## 34.67201 46.44437 31.99498 38.41326 38.41326</code></pre>
<p>The above code reassures us that the predictions given on a <code>uRegress</code> object are the same as the predictions given on a <code>lm</code> object. The same is true for all of the other types of regression possible with <code>regress()</code>.</p>
</div>
</div>
<div id="diagnostics" class="section level1">
<h1>Diagnostics</h1>
<p>Besides the other tools we have already covered that can double as diagnostic tools - scatterplots, boxplots - sometimes it is useful to look at residuals calculated from a regression model. Objects of class <code>uRegress</code>, like all other regression objects, have a function to extract residuals. The function we use is <code>uresiduals()</code>, which can return unstandardized, standardized, studentized, or jackknifed residuals. If we want the residuals from the model regressing age on ldl, it is easy to get both studentized and jackknifed residuals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ldlReg &lt;-<span class="st"> </span><span class="kw">regress</span>(<span class="st">&quot;mean&quot;</span>, age ~<span class="st"> </span>ldl, <span class="dt">data =</span> mri)

student.resid &lt;-<span class="st"> </span><span class="kw">uResiduals</span>(ldlReg, <span class="st">&quot;studentized&quot;</span>)
jack.resid &lt;-<span class="st"> </span><span class="kw">uResiduals</span>(ldlReg, <span class="st">&quot;jackknife&quot;</span>)

<span class="kw">head</span>(student.resid, <span class="dt">n =</span> <span class="dv">5</span>)</code></pre></div>
<pre><code>##          1          2          3          4          5 
## -0.4676531  1.1641617  2.8293373 -0.5011149 -0.8294973</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(jack.resid, <span class="dt">n =</span> <span class="dv">5</span>)</code></pre></div>
<pre><code>##          1          2          3          4          5 
## -0.4674003  1.1644483  2.8431637 -0.5008553 -0.8293181</code></pre>
<p>As with prediction, the residuals can be returned from any regression type allowed by <code>regress()</code>.</p>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
